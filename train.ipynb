{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927c0c2-34d7-4f5f-b5f3-b5e662a7ba67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from vpt.agent import resize_image\n",
    "\n",
    "from src.policy.vpt import load\n",
    "from src.policy.ppo import BatchEpisode, PPO\n",
    "from src.policy.policy import VPTPolicy\n",
    "from src.policy.mt_ppo import MTBatchEpisode, MTPPO\n",
    "from src.policy.mt_policy import MTVPTPolicy\n",
    "\n",
    "from src.collector.conc import MultiThreadCollector, Worker\n",
    "from src.collector.mt_collect import MTCollector\n",
    "\n",
    "from src.environment.env import eval_task_ids, eval_task_specs, make_eval_env\n",
    "\n",
    "from src.reward.mineclip import MineCLIP, soften, min_clip, zero_out_decreased, hidden_dim as clip_embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df546674-9058-451b-8b5a-411f378b99df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['MINEDOJO_HEADLESS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    ppo=dict(clip=0.2, vf_loss_scale=1,\n",
    "             gamma=0.999, gae_lambda=0.95, normalize_gae=True,\n",
    "             policy_reg_scale=0.3, lr=1e-4),\n",
    "    ppo_step=dict(n_max_epoch=5, context_l=100, max_context=4,\n",
    "                  batch_size=80, target_kl=0.1),\n",
    "    policy_reg_scale_decay=0.999,\n",
    "    adapter=dict(\n",
    "        dim_factor=8,\n",
    "    ),\n",
    "    n_episode_in_batch=10,\n",
    "    time_limit=200,\n",
    "    reward=dict(\n",
    "        soften_window=50,\n",
    "        min_clip=21,\n",
    "        scale=0.005,\n",
    "    ),\n",
    "    n_iter=1000,\n",
    ")\n",
    "args = dict(\n",
    "    gpu=0,\n",
    "    n_worker=10,\n",
    "    eval_period=20,\n",
    "    n_eval_episode=10,\n",
    "    process_batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998eced7-98a8-44e2-9230-333a7386cc49",
   "metadata": {},
   "source": [
    "## MineDojo environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05eb18c-8baa-4fe1-b72f-5b98a986ed61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vpt = load(\n",
    "    './asset/vpt/foundation-model-3x.model',\n",
    "    './asset/vpt/bc-house-3x.weights',\n",
    "    context_l=config['ppo_step']['context_l']\n",
    ")\n",
    "vpt_policy = VPTPolicy(copy.deepcopy(vpt), event_level_control=False).to(args['gpu'])\n",
    "policy = MTVPTPolicy(vpt, clip_embed_dim, config['adapter']['dim_factor'], event_level_control=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1d1cd-b650-4475-a7e1-85ef9ea499b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "workers = []\n",
    "dummy_env_spec = eval_task_specs[eval_task_ids[0]]\n",
    "for _ in range(args['n_worker']):\n",
    "    worker = Worker(MTCollector(\n",
    "        make_eval_env(dummy_env_spec), time_limit=config['time_limit']\n",
    "    ))\n",
    "    workers.append(worker)\n",
    "\n",
    "conc_collector = MultiThreadCollector(workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc0419-9a37-461b-adb9-fff8611c50d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mineclip = MineCLIP('./asset/mineclip/attn.pth')\n",
    "for param in mineclip.parameters():\n",
    "    param.requires_grad = False\n",
    "mineclip.eval()\n",
    "mineclip.to(args['gpu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c4c35e-d431-4a63-bf98-34ec0011f7c3",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f060759-8bb9-40ac-bfef-ec58f8ab3630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = MTPPO(policy, vpt_policy, **config['ppo']).to(args['gpu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce863d18-d6a6-44f4-a72c-45d54c694262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load = torch.load('./asset/task_proposals.pt')\n",
    "polished = load['polished']\n",
    "world_seeds = load['world_seeds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca44488-9413-4127-8ca4-cc45f3d9d573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_task_envs = []\n",
    "for ii, eval_task_id in enumerate(eval_task_ids):\n",
    "    for world_seed in world_seeds:\n",
    "        print(len(tr_task_envs), end=' ')\n",
    "    \n",
    "        # building env\n",
    "        env_spec = eval_task_specs[eval_task_id]\n",
    "\n",
    "        env_spec['world_seed'] = world_seed.item()\n",
    "        env_spec['fast_reset'] = False \n",
    "        env_spec['event_level_control'] = False\n",
    "        \n",
    "        env_spec['target_quantities'] = 999999 # disable ground-truth success criteria\n",
    "    \n",
    "        env = make_eval_env(env_spec)\n",
    "        env.unwrapped._bridge_env = None\n",
    "        tr_task_envs.append(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091f0ec9-07df-458e-9499-2c5976818902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_task_prompts = []\n",
    "for ii, p in enumerate(polished):\n",
    "    if \":\" in p:\n",
    "        p = p.split(': ')[1]\n",
    "    print(p)\n",
    "    if ii % 5 == 4: print()\n",
    "    \n",
    "    tr_task_prompts.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09357536-7d17-4e75-8d4a-f5f35fd3f8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_task_embeds = []\n",
    "for prompt in tr_task_prompts:\n",
    "    print(len(tr_task_embeds), end=' ')\n",
    "    \n",
    "    task_embed = mineclip.embed_text(prompt).cpu()\n",
    "    task_embed = task_embed / task_embed.norm(p=2, dim=-1, keepdim=True)\n",
    "    task_embed = task_embed[0]\n",
    "    \n",
    "    tr_task_embeds.append(task_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbb791c-2b04-479b-811f-f3800b286d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_envs = []\n",
    "for eval_task_id in eval_task_ids:\n",
    "    env_spec = eval_task_specs[eval_task_id]\n",
    "    \n",
    "    env_spec['fast_reset'] = False\n",
    "    env_spec['event_level_control'] = False\n",
    "    \n",
    "    eval_env = make_eval_env(env_spec)\n",
    "    eval_env.unwrapped._bridge_env = None\n",
    "    eval_envs.append(eval_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_task_prompts = [\n",
    "    'get milk from a cow',\n",
    "    'shear a sheep and get some wool',\n",
    "    'hunt a chicken and get its meat',\n",
    "    'collect logs',\n",
    "    'kill a cow',\n",
    "    'kill a sheep',\n",
    "    'kill a spider',\n",
    "    'kill a zombie',\n",
    "]\n",
    "oracle_task_prompts = mineclip.embed_text(oracle_task_prompts).cpu()[0]\n",
    "oracle_task_prompts = oracle_task_prompts / oracle_task_prompts.norm(p=2, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e103e6af-9038-4d70-aa38-7a26bfc11e73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for collect_i in range(config['n_iter']): \n",
    "    log = {'collect_i': collect_i, 'episode_i': collect_i*config['n_episode_in_batch']}\n",
    "\n",
    "    # train env\n",
    "    with torch.cuda.amp.autocast(), policy.expl():\n",
    "        time1 = time.perf_counter()\n",
    "        \n",
    "        # collector\n",
    "        for tr_env, task_embed in zip(tr_task_envs, tr_task_embeds):\n",
    "            conc_collector.submit(policy, copy.deepcopy(tr_env), None, task_embed)\n",
    "        episodes = conc_collector.wait()\n",
    "        log['time_collect'] = time.perf_counter()-time1\n",
    "        \n",
    "        time1 = time.perf_counter()\n",
    "        \n",
    "        # reward\n",
    "        mineclip.to(args['gpu'])\n",
    "        for ep_idx, episode in enumerate(episodes):\n",
    "            episode.rewarded_states = torch.as_tensor(\n",
    "                np.stack([\n",
    "                    resize_image(s['rgb'][:, 32:608], (256, 160))\n",
    "                    for s in episode.states\n",
    "                ])\n",
    "            ).permute(0, 3, 1, 2).to(args['gpu'])\n",
    "                \n",
    "            text_embed = tr_task_embeds[ep_idx]\n",
    "\n",
    "            video_embed = mineclip.embed_video(\n",
    "                episode.rewarded_states, process_batch_size=args['process_batch_size']\n",
    "            )\n",
    "            \n",
    "            episode.rewards = config['reward']['scale'] * min_clip(\n",
    "                soften(\n",
    "                    mineclip.compute_reward(\n",
    "                            text_embed.to(args['gpu']), video_embed.to(args['gpu'])\n",
    "                    ),\n",
    "                    config['reward']['soften_window']\n",
    "                ), config['reward']['min_clip']\n",
    "            )\n",
    "            episode.rewards = zero_out_decreased(episode.rewards)\n",
    "            \n",
    "            del video_embed\n",
    "            episode.rewarded_states = episode.rewarded_states.to('cpu')\n",
    "        mineclip.to('cpu')\n",
    "        log['time_reward'] = time.perf_counter()-time1\n",
    "\n",
    "    log['tr_return'] = np.mean([sum(episode.rewards) for episode in episodes])\n",
    "    log['tr_epi_len'] = np.mean([len(episode.rewards) for episode in episodes])\n",
    "\n",
    "    # eval env\n",
    "    if collect_i % args['eval_period'] == 0:\n",
    "        time1 = time.perf_counter()\n",
    "        \n",
    "        # collector\n",
    "        with torch.cuda.amp.autocast(), policy.expl():\n",
    "            for task_idx, (eval_env, eval_task_embed) in enumerate(zip(eval_envs, oracle_task_prompts)):\n",
    "                for _ in range(args['n_eval_episode']):\n",
    "                    conc_collector.submit(policy, copy.deepcopy(eval_env), None, eval_task_embed)\n",
    "            eval_episodes = conc_collector.wait()\n",
    "    \n",
    "            taskw_eval_episodes = np.array(eval_episodes, np.object).reshape(len(eval_envs), args['n_eval_episode'])\n",
    "        log['time_eval_collect'] = time.perf_counter()-time1\n",
    "        \n",
    "        # success check\n",
    "        taskw_success_rate = [\n",
    "            np.mean([any(eval_episode.rewards) for eval_episode in eval_episodes])\n",
    "            for eval_episodes in taskw_eval_episodes\n",
    "        ]\n",
    "        log['eval_success_rate'] = {\n",
    "            task_idx: success_rate\n",
    "            for task_idx, success_rate in enumerate(taskw_success_rate) \n",
    "        }\n",
    "        log['eval_avg_success_rate'] = np.mean(taskw_success_rate)\n",
    "\n",
    "    # logging\n",
    "    time1 = time.perf_counter()\n",
    "    stat = trainer.step(\n",
    "        episodes, **config['ppo_step'],\n",
    "        process_batch_size=args['process_batch_size']\n",
    "    )\n",
    "    log['time_ppo'] = time.perf_counter()-time1\n",
    "    log.update(stat)\n",
    "    \n",
    "    log['policy_reg_scale'] = trainer.policy_reg_scale\n",
    "    trainer.policy_reg_scale *= config['policy_reg_scale_decay']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
